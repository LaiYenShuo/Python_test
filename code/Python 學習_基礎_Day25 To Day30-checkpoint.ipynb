{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二十五天 機器學習（5）整體學習\n",
    "\n",
    "\n",
    "##### https://ithelp.ithome.com.tw/articles/10187452"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "\n",
    "### Bagging 是 Bootstrap Aggregating 的簡稱，透過統計學的 Bootstrap sampling 得到不同的訓練資料，然後根據這些訓練資料得到一系列的基本分類器，假如演算法產生了 5 個基本分類器，她們對某個觀測值的預測結果分別為 1, 0, 1, 1, 1，那麼 Bagging 演算法的輸出結果就會是 1，這個過程稱之為基本分類器的投票。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8283582089552238"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#--------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
    "\n",
    "# loading data\n",
    "\n",
    "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
    "titanic_train = pd.read_csv(url)\n",
    "\n",
    "# 填補遺漏值\n",
    "\n",
    "age_median = np.nanmedian(titanic_train[\"Age\"])\n",
    "new_Age = np.where(titanic_train[\"Age\"].isnull(), age_median,\n",
    "                   titanic_train[\"Age\"])\n",
    "titanic_train[\"Age\"] = new_Age\n",
    "\n",
    "# create dummy variables\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_Sex = label_encoder.fit_transform(titanic_train[\"Sex\"])\n",
    "\n",
    "# create test and train data\n",
    "titanic_X = pd.DataFrame([\n",
    "    titanic_train[\"Pclass\"],\n",
    "    encoded_Sex,\n",
    "    titanic_train[\"Age\"]\n",
    "]).T\n",
    "# titanic_X\n",
    "titanic_y = titanic_train[\"Survived\"]\n",
    "train_X, test_X, train_y, test_y = cross_validation.train_test_split(\n",
    "titanic_X, titanic_y, test_size = 0.3)\n",
    "\n",
    "# create bagging model\n",
    "bag = ensemble.BaggingClassifier(n_estimators = 100)\n",
    "bag.fit(train_X, train_y)\n",
    "\n",
    "# predicted\n",
    "\n",
    "test_y_predicted = bag.predict(test_X)\n",
    "test_y_predicted\n",
    "# accuraacy\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost\n",
    "\n",
    "### AdaBoost 同樣是基於數個基本分類器的整體學習演算法，跟前述 Bagging 演算法不同的地方在於，她在形成基本分類器時除了隨機生成，還會針對在前一個基本分類器中被分類錯誤的觀測值提高抽樣權重，使得該觀測值在下一個基本分類器形成時有更高機率被選入，藉此提高被正確分類的機率，簡單來說，她是個具有即時調節觀測值抽樣權重的進階 Bagging 演算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7798507462686567"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
    "\n",
    "# 載入資料\n",
    "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
    "titanic_train = pd.read_csv(url)\n",
    "\n",
    "# 填補遺漏值\n",
    "age_median = np.nanmedian(titanic_train[\"Age\"])\n",
    "new_Age = np.where(titanic_train[\"Age\"].isnull(), age_median,\n",
    "                   titanic_train[\"Age\"])\n",
    "titanic_train[\"Age\"] = new_Age\n",
    "\n",
    "# 創造 dummy variables\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_Sex = label_encoder.fit_transform(titanic_train[\"Sex\"])\n",
    "\n",
    "# 建立訓練與測試資料\n",
    "titanic_X = pd.DataFrame([titanic_train[\"Pclass\"],\n",
    "                         encoded_Sex,\n",
    "                         titanic_train[\"Age\"]\n",
    "]).T\n",
    "\n",
    "titanic_y = titanic_train[\"Survived\"]\n",
    "train_X, test_X, train_y, test_y = cross_validation.train_test_split(\n",
    "    titanic_X, titanic_y, test_size = 0.3)\n",
    "\n",
    "# 建立 boosting 模型\n",
    "\n",
    "boost = ensemble.AdaBoostClassifier(n_estimators = 100)\n",
    "boost.fit = boost.fit(train_X, train_y)\n",
    "\n",
    "# 預測\n",
    "\n",
    "test_y_predicted = boost.predict(test_X)\n",
    "\n",
    "# 績效\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
    "accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二十六天  機器學習（6）隨機森林與支持向量機"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 隨機森林\n",
    "\n",
    "### 隨機森林演算法會對資料從列方向（觀測值方向）與欄方向（變數方向）進行 Bootstrap sampling，得到不同的訓練資料，然後根據這些訓練資料得到一系列的決策樹分類器，假如產生了 5 個決策樹分類器，她們對某個觀測值的預測結果分別為 1, 0, 1, 1, 1，那麼隨機森林演算法的輸出結果就會是 1，這個過程與 Bagging 演算法相同，同樣稱為基本分類器的投票。隨機森林演算法在面對變數具有多元共線性或者不平衡資料（Unbalanced data）的情況時是倍受青睞的演算法。\n",
    "\n",
    "## AUC\n",
    "\n",
    "### 在二元分類模型裡面，除了我們一直使用的準確率（Accuracy）以外，其實還有許多由 Confusion matrix 所衍生的績效指標，像是精確度（Precision）或者召回率（Recall）等，其中 AUC 是一個常見指標，它同時考慮假警報率（False alarm rate）與命中率（True positive rate），AUC 愈接近 1，就表示分類效果愈好；愈接近 0.5 就表示分類效果愈差不好。\n",
    "\n",
    "|效果  | AUC 區間 |\n",
    "|-----||\n",
    "|傑出\t| 0.9-1.0 |\n",
    "||\n",
    "|優秀\t| 0.8-0.9 |\n",
    "||\n",
    "|普通\t| 0.7-0.8 |\n",
    "||\n",
    "|不好\t| 0.6-0.7 |\n",
    "||\n",
    "|差勁\t| 0.5-0.6 |\n",
    "||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8208955223880597"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.8018518518518519"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, ensemble, preprocessing, metrics\n",
    "\n",
    "# 載入資料\n",
    "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
    "titanic_train = pd.read_csv(url)\n",
    "\n",
    "# 填補遺漏值\n",
    "age_median = np.nanmedian(titanic_train[\"Age\"])\n",
    "new_Age = np.where(titanic_train[\"Age\"].isnull(), age_median,\n",
    "                   titanic_train[\"Age\"])\n",
    "titanic_train[\"Age\"] = new_Age\n",
    "\n",
    "# 創造 dummy variables\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_Sex = label_encoder.fit_transform(titanic_train[\"Sex\"])\n",
    "\n",
    "# 建立訓練與測試資料\n",
    "titanic_X = pd.DataFrame([titanic_train[\"Pclass\"],\n",
    "                         encoded_Sex,\n",
    "                         titanic_train[\"Age\"]\n",
    "]).T\n",
    "titanic_y = titanic_train[\"Survived\"]\n",
    "train_X, test_X, train_y, test_y = cross_validation.train_test_split(\n",
    "    titanic_X, titanic_y, test_size = 0.3)\n",
    "\n",
    "# 建立 random forest 模型 \n",
    "\n",
    "forest = ensemble.RandomForestClassifier(n_estimators = 100)\n",
    "forest.fit = forest.fit(train_X, train_y)\n",
    "\n",
    "# predicted\n",
    "\n",
    "test_y_predicted = forest.predict(test_X)\n",
    "\n",
    "# accuracy\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
    "accuracy\n",
    "\n",
    "# ACU\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_y, test_y_predicted)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量機\n",
    "\n",
    "### 支持向量機是一種最小化結構風險（Structural risk）的演算法，何謂結構型風險？機器學習的內涵在於假設一個類似模型去逼近真實模型，而量化類似模型與真實模型之間差距的方式，跟我們在計算績效（準確率）用的概念是相同的，我們用類似模型預測的結果去跟答案比較。許多的分類器可以在訓練資料上達到很高的正確率（稱作 Overfitting），但是卻失去應用在實際問題的推廣能力（Generalization ability）。\n",
    "\n",
    "### 資料科學家將分類器在訓練樣本可能過度配適的風險稱為 Empirical risk，分類器的推廣能力不足的風險稱為 Generalization risk，兩者的總和即為結構風險，而支持向量機就是在兩者之間取得最佳平衡點，進而得到一個在訓練資料績效不錯，亦能推廣適用的類似模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.7723880597014925"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.742797118847539"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation, svm, preprocessing, metrics\n",
    "\n",
    "# 載入資料\n",
    "url = \"https://storage.googleapis.com/2017_ithome_ironman/data/kaggle_titanic_train.csv\"\n",
    "titanic_train = pd.read_csv(url)\n",
    "\n",
    "# 填補遺漏值\n",
    "age_median = np.nanmedian(titanic_train[\"Age\"])\n",
    "new_Age = np.where(titanic_train[\"Age\"].isnull(), age_median,\n",
    "                   titanic_train[\"Age\"])\n",
    "titanic_train[\"Age\"] = new_Age\n",
    "\n",
    "# 創造 dummy variables\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "encoded_Sex = label_encoder.fit_transform(titanic_train[\"Sex\"])\n",
    "\n",
    "# 建立訓練與測試資料\n",
    "titanic_X = pd.DataFrame([titanic_train[\"Pclass\"],\n",
    "                         encoded_Sex,\n",
    "                         titanic_train[\"Age\"]\n",
    "]).T\n",
    "titanic_y = titanic_train[\"Survived\"]\n",
    "train_X, test_X, train_y, test_y = cross_validation.train_test_split(\n",
    "    titanic_X, titanic_y, test_size = 0.3)\n",
    "\n",
    "# 建立 SVC 模型\n",
    "svc = svm.SVC()\n",
    "svc.fit(train_X, train_y)\n",
    "\n",
    "test_y_predicted = svc.predict(test_X)\n",
    "\n",
    "accuracy = metrics.accuracy_score(test_y, test_y_predicted)\n",
    "accuracy\n",
    "\n",
    "# ACU\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(test_y, test_y_predicted)\n",
    "auc = metrics.auc(fpr, tpr)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二十七天 深度學習 TensorFlow\n",
    "scikit-learn https://scikit-learn.org/stable/tutorial/machine_learning_map/\n",
    "\n",
    "https://ithelp.ithome.com.tw/articles/10187702\n",
    "#### 目前主流的深度學習框架（Framework）有 Caffe、TensorFlow、Theano、Torch 與 Keras，其中 Keras 是可以使用 API 呼叫方式同時使用 TensorFlow 與 Theano 的高階框架，我們選擇入門的框架是 TensorFlow。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 快速實作\n",
    "\n",
    "#### 讓我們跟著官方文件實作第一個 TensorFlow 程式，我們要利用梯度遞減（Gradient descent）的演算法找出已知迴歸模型（y = 0.1x + 0.3）的係數（0.1）與截距（0.3）並對照結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0.8025353] [-0.11646853]\n",
      "20 [0.30289719] [0.19096775]\n",
      "40 [0.15727435] [0.2692221]\n",
      "60 [0.11616755] [0.29131195]\n",
      "80 [0.10456382] [0.29754752]\n",
      "100 [0.10128829] [0.2993077]\n",
      "120 [0.10036366] [0.2998046]\n",
      "140 [0.10010263] [0.29994485]\n",
      "160 [0.10002895] [0.29998446]\n",
      "180 [0.10000816] [0.29999563]\n",
      "200 [0.1000023] [0.2999988]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# data\n",
    "x_data = np.random.rand(1000).astype(np.float32)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# W 指的是係數，斜率介於 -1 至 1 之間\n",
    "# b 指的是截距，從 0 開始逼近任意數字\n",
    "# y 指的是預測值\n",
    "W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "y = W * x_data + b\n",
    "\n",
    "# 我們的目標是要讓 loss（MSE）最小化\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.5)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 初始化\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 將神經網絡圖畫出來\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 將迴歸線的係數與截距模擬出來\n",
    "# 每跑 20 次把當時的係數與截距印出來\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train)\n",
    "    if step % 20 == 0:\n",
    "        print(step, sess.run(W), sess.run(b))\n",
    "        \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基礎使用\n",
    "### 應用 TensorFlow 的時候我們得了解她的名詞與定義：\n",
    "\n",
    "|名詞\t| 定義|\n",
    "|---||\n",
    "|Graphs\t| 建立運算元|\n",
    "|Sessions | 執行運算|\n",
    "|Tensors | 資料|\n",
    "|Variables | 變數|\n",
    "|Feeds | 資料輸入|\n",
    "|Fetches | 資料輸出|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "# 建立運算元\n",
    "\n",
    "import tensorflow as tf\n",
    "# 1x2 matrix\n",
    "matrix1 = tf.constant([[3,3]])\n",
    "\n",
    "# 2x1 matrix\n",
    "matrix2 = tf.constant([\n",
    "    [2],\n",
    "    [2]\n",
    "])\n",
    "\n",
    "# matmul() 表矩陣相乘 ANS 12\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "# 現在我們的運算元已經建立好，有三個節點，分別是兩個 constant() \n",
    "# 與一個 matmul()，意即神經網絡的圖已經建構完成，但是尚未執行運算。\n",
    "\n",
    "# 執行運算 法一 Session\n",
    "sess = tf.Session()\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[12]])]\n"
     ]
    }
   ],
   "source": [
    "# 建立運算元\n",
    "\n",
    "import tensorflow as tf\n",
    "# 1x2 matrix\n",
    "matrix1 = tf.constant([[3,3]])\n",
    "\n",
    "# 2x1 matrix\n",
    "matrix2 = tf.constant([\n",
    "    [2],\n",
    "    [2]\n",
    "])\n",
    "\n",
    "# matmul() 表矩陣相乘 ANS 12\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "# 現在我們的運算元已經建立好，有三個節點，分別是兩個 constant() \n",
    "# 與一個 matmul()，意即神經網絡的圖已經建構完成，但是尚未執行運算。\n",
    "\n",
    "# 法二 不需關閉 Session\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([product])\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12]]\n"
     ]
    }
   ],
   "source": [
    "# 法三 要將 matrix1 設定為 Variable 然後再由她來初始化。\n",
    "# 啟動 Session\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# 1x2 matrix \n",
    "# notice change variable\n",
    "\n",
    "matrix1 = tf.Variable([[3, 3]])\n",
    "\n",
    "# 2x1 matrix\n",
    "matrix2 = tf.constant([\n",
    "    [2],\n",
    "    [2]\n",
    "])\n",
    "\n",
    "# 初始化 matrix1\n",
    "matrix1.initializer.run()\n",
    "\n",
    "# run\n",
    "result = tf.matmul(matrix1, matrix2)\n",
    "print(result.eval())\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "21\n",
      "41\n",
      "61\n",
      "81\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "# Variable\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# set variable\n",
    "state = tf.Variable(0, name = \"counter\")\n",
    "\n",
    "# 每次加 1 之後更新 state\n",
    "one = tf.constant(1)\n",
    "new_value = tf.add(state, one)\n",
    "update = tf.assign(state, new_value)\n",
    "\n",
    "# 初始化\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# run\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    # print 初始值\n",
    "    print(sess.run(state))\n",
    "    # 更新三次分別印出 variable\n",
    "    for _ in range(101):\n",
    "        sess.run(update)\n",
    "        if _ % 20 == 0:\n",
    "            print(sess.run(state))\n",
    "        \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([21.], dtype=float32)]\n",
      "[array([8]), array([15])]\n"
     ]
    }
   ],
   "source": [
    "# 資料輸入\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "# 將 input1 以 7 輸入，input2 以 3 輸入\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([output], feed_dict = {input1: [7], input2: [3]}))\n",
    "\n",
    "# 資料輸出\n",
    "\n",
    "input1 = tf.constant([3])\n",
    "input2 = tf.constant([5])\n",
    "added = tf.add(input1, input2)\n",
    "multiplied = tf.multiply(input1, input2)\n",
    "\n",
    "# 輸出 added and multiplied\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run([added, multiplied])\n",
    "    print(result)\n",
    "    \n",
    "sess.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二十八天 深度學習（2）TensorBoard\n",
    "\n",
    "## 整理程式\n",
    "#### 在視覺化之前，我們先用較模組化的寫法：MorvanZhou@GitHub 的範例程式改寫昨天的程式。 https://github.com/MorvanZhou/tutorials/blob/master/tensorflowTUT/tf15_tensorboard/full_code.py\n",
    "\n",
    "## 改寫架構\n",
    "#### 定義一個添加層的函數：add_layer()\n",
    "#### 準備資料（Inputs）\n",
    "#### 建立 Feeds（使用 tf.placeholder() 方法）來傳入資料\n",
    "#### 添加隱藏層與輸出層\n",
    "#### 定義 loss 與要使用的 Optimizer（使用梯度遞減）\n",
    "#### 初始化 Graph 並開始運算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31843308\n",
      "0.0021085583\n",
      "0.00091395306\n",
      "0.00057793804\n",
      "0.00036607255\n",
      "0.00023190337\n",
      "0.00014692132\n",
      "9.308601e-05\n",
      "5.898029e-05\n",
      "3.737109e-05\n",
      "2.3680548e-05\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定義一個添加函數\n",
    "def add_layer(inputs, input_tensors, output_tensors, activation_function = None):\n",
    "    W = tf.Variable(tf.random_normal([input_tensors, output_tensors]))\n",
    "    b = tf.Variable(tf.zeros([1, output_tensors]))\n",
    "    formula = tf.add(tf.matmul(inputs, W), b)\n",
    "    if activation_function is None:\n",
    "        outputs = formula\n",
    "    else:\n",
    "        outputs = activation_function(formula)\n",
    "    return outputs\n",
    "\n",
    "# 準備資料\n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# 建立  Feeds\n",
    "x_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "y_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# 添加一個隱藏層\n",
    "hidden_layer = add_layer(x_feeds, input_tensors = 1\n",
    "                         , output_tensors = 10, activation_function = None)\n",
    "\n",
    "# 添加一個輸出層\n",
    "output_layer = add_layer(hidden_layer, input_tensors = 10\n",
    "                         , output_tensors = 1, activation_function = None)\n",
    "\n",
    "# 定義 `loss` 與要使用的 Optimizer\n",
    "loss = tf.reduce_mean(tf.square(y_feeds - output_layer))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "# 初始化 Graph 並開始運算\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "for step in range(201):\n",
    "    sess.run(train, feed_dict = {x_feeds: x_data, y_feeds: y_data})\n",
    "    if step % 20 == 0:\n",
    "        print(sess.run(loss, feed_dict = {x_feeds: x_data, y_feeds: y_data}))\n",
    "        \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 視覺化\n",
    "\n",
    "#### 接著我們要在模組化的程式中使用 with tf.name_scope(): 為每個運算元命名，然後在神經網絡運算初始之後，利用 tf.summary.FileWriter() 將視覺化檔案輸出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# def a add layer\n",
    "def add_layer(inputs, in_tensors, ou_tensors, activation_function = None):\n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            W = tf.Variable(tf.random_normal([in_tensors, ou_tensors]))\n",
    "        with tf.name_scope('Biases'):\n",
    "            b = tf.Variable(tf.zeros([1, ou_tensors]))\n",
    "        with tf.name_scope('Formula'):\n",
    "            formula = tf.add(tf.matmul(inputs, W), b)\n",
    "        if activation_function is None:\n",
    "            outputs = formula\n",
    "        else:\n",
    "            outputs = activation_function(formula)\n",
    "        return outputs\n",
    "\n",
    "# 準備資料\n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# 建立 Feeds\n",
    "with tf.name_scope('Inputs'):\n",
    "    x_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "    y_feeds = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "# 添加 1 個隱藏層\n",
    "hidden_layer = add_layer(x_feeds, in_tensors = 1\n",
    "                         , ou_tensors = 10, activation_function = None)\n",
    "\n",
    "# 添加 1 個輸出層\n",
    "output_layer = add_layer(hidden_layer, in_tensors = 10\n",
    "                         , ou_tensors = 1, activation_function = None)\n",
    "\n",
    "# 定義 `loss` 與要使用的 Optimizer\n",
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y_feeds - output_layer))\n",
    "with tf.name_scope('Train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "    \n",
    "# 初始化 Graph\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "# 將視覺化輸出\n",
    "\n",
    "writer = tf.summary.FileWriter(\"TensorBoard/\", graph = sess.graph)\n",
    "\n",
    "# start\n",
    "sess.run(init)\n",
    "for step in range(201):\n",
    "    sess.run(train, feed_dict = {x_feeds: x_data, y_feeds: y_data})\n",
    "    \n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 視覺化（2）\n",
    "\n",
    "#### 我們除了可以使用 with tf.name_scope(): 為每個運算元命名，我們還可以在使用 tf.Variable() 或者 tf.placeholder() 建立變數或輸入資料時，利用 name = 參數進行命名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def add_layer(inputs, in_tensors, ou_tensors, activation_function = None):\n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            W = tf.Variable(tf.random_normal([in_tensors, ou_tensors]), name = 'W')\n",
    "        with tf.name_scope('Biases'):\n",
    "            b = tf.Variable(tf.zeros([1, ou_tensors]), name = 'b')\n",
    "        with tf.name_scope('Formula'):\n",
    "            formula = tf.add(tf.matmul(inputs, W), b)\n",
    "        if activation_function is None:\n",
    "            outputs = formula\n",
    "        else:\n",
    "            outputs = activation_function(formula)\n",
    "        return outputs\n",
    "    \n",
    "# \n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# Feeds\n",
    "with tf.name_scope('Inputs'):\n",
    "    x_feeds = tf.placeholder(tf.float32, shape = [None, 1], name = 'x_inputs')\n",
    "    y_feeds = tf.placeholder(tf.float32, shape = [None, 1], name = 'y_inputs')\n",
    "    \n",
    "#\n",
    "hidden_layer = add_layer(x_feeds, in_tensors = 1, ou_tensors = 10, activation_function = None)\n",
    "\n",
    "#\n",
    "ou_layer = add_layer(hidden_layer, in_tensors = 10, ou_tensors = 1, activation_function = None)\n",
    "\n",
    "# 定義 `loss` 與要使用的 Optimizer\n",
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y_feeds - ou_layer))\n",
    "with tf.name_scope('Train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "    \n",
    "# \n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "# \n",
    "writer = tf.summary.FileWriter(\"TensorBoard/\", graph = sess.graph)\n",
    "\n",
    "sess.run(init)\n",
    "for step in range(201):\n",
    "    sess.run(train, feed_dict = {x_feeds: x_data, y_feeds: y_data})\n",
    "    \n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 視覺化（3）\n",
    "\n",
    "#### 我們很快就有了疑問：那麼其他頁籤的功能呢？TensorBoard 還能夠將訓練過程視覺化呈現，我們利用 tf.summary.histogram() 與 tf.summary.scalar() 將訓練過程記錄起來，然後在 Scalars 與 Histograms 頁籤檢視。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def add_layer(inputs, in_tensors, ou_tensors, n_layer, activation_function = None):\n",
    "    layer_name = 'layer%s' % n_layer\n",
    "    with tf.name_scope('Layer'):\n",
    "        with tf.name_scope('Weights'):\n",
    "            W = tf.Variable(tf.random_normal([in_tensors, ou_tensors]), name = 'W')\n",
    "            tf.summary.histogram(name = layer_name + '/Weights', values = W)\n",
    "        with tf.name_scope('Biases'):\n",
    "            b = tf.Variable(tf.zeros([1, ou_tensors]), name = 'b')\n",
    "            tf.summary.histogram(name = layer_name + '/Biases', values = b)\n",
    "        with tf.name_scope('Formula'):\n",
    "            formula = tf.add(tf.matmul(inputs, W), b)\n",
    "        if activation_function is None:\n",
    "            outputs = formula\n",
    "        else:\n",
    "            outputs = activation_function(formula)\n",
    "        tf.summary.histogram(name = layer_name + '/Outputs', values = outputs)\n",
    "        return outputs\n",
    "    \n",
    "# data\n",
    "x_data = np.random.rand(100)\n",
    "x_data = x_data.reshape(len(x_data), 1)\n",
    "y_data = x_data * 0.1 + 0.3\n",
    "\n",
    "# 建立 Feeds\n",
    "with tf.name_scope('Inputs'):\n",
    "    x_feeds = tf.placeholder(tf.float32, shape = [None, 1], name = 'x_inputs')\n",
    "    y_feeds = tf.placeholder(tf.float32, shape = [None, 1], name = 'y_inputs')\n",
    "# hidden\n",
    "\n",
    "hidden_layer = add_layer(x_feeds, in_tensors = 1, ou_tensors = 10,\n",
    "                         n_layer = 1, activation_function = None)\n",
    "\n",
    "# \n",
    "output_layer = add_layer(hidden_layer, in_tensors = 10, ou_tensors = 1, n_layer = 2, activation_function = None)\n",
    "# def loss optimizer\n",
    "\n",
    "with tf.name_scope('Loss'):\n",
    "    loss = tf.reduce_mean(tf.square(y_feeds - output_layer))\n",
    "    tf.summary.scalar('loss', loss)\n",
    "with tf.name_scope('Train'):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.01)\n",
    "    train = optimizer.minimize(loss)\n",
    "    \n",
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "\n",
    "# 將視覺化輸出\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\"TensorBoard/\", graph = sess.graph)\n",
    "\n",
    "# start\n",
    "sess.run(init)\n",
    "for step in range(400):\n",
    "    sess.run(train, feed_dict = {x_feeds: x_data, y_feeds: y_data})\n",
    "    if step % 20 == 0:\n",
    "        result = sess.run(merged, feed_dict = {x_feeds: x_data, y_feeds: y_data})\n",
    "        writer.add_summary(result, step)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二十九天 深度學習（3）MNIST 手寫數字辨識\n",
    "\n",
    "### 讀入 MNIST\n",
    "#### 如同在 scikit-learn 套件中讀入 iris 一般，在 TensorFlow 套件中讀入 MNIST 同樣是很容易的，不論是訓練資料或者測試資料，都有分 images 與 labels 屬性，我們簡單跟 scikit-learn 套件做個對照：\n",
    "\n",
    "|套件\t| 自變數 X\t| 目標變數 y |\n",
    "|---|||\n",
    "|sklearn | data\t|target|\n",
    "|tensorflow\t| images | labels|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(55000, 784)\n",
      "(55000, 10)\n",
      "(10000, 784)\n",
      "(10000, 10)\n",
      "---\n",
      "3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21a4f61c748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "### 讀入 MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "# 檢視結構\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(\"---\")\n",
    "\n",
    "# 檢視一個觀測值\n",
    "#print(x_train[1, :])\n",
    "print(np.argmax(y_train[1, :])) # 第一張訓練圖片的真實答案\n",
    "# print\n",
    "first_train_img = np.reshape(x_train[1, :], (28, 28))\n",
    "plt.matshow(first_train_img, cmap = plt.get_cmap('Blues')) # gray\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax 函數\n",
    "\n",
    "#### 我們需要透過 Softmax 函數將分類器輸出的分數（Evidence）轉換為機率（Probability），然後依據機率作為預測結果的輸出，可想而知深度學習模型的輸出層會是一個 Softmax 函數。\n",
    "##### https://ithelp.ithome.com.tw/articles/10187912\n",
    "$y = \\text{softmax}(Wx + b)$\n",
    "\n",
    "## Cross-entropy\n",
    "#### 不同於我們先前使用 Mean Squared Error 定義 Loss，在這個深度學習模型中我們改用 Cross-entropy 來定義 Loss。\n",
    "\n",
    "## TensorFlow 實作\n",
    "#### 我們建立一個可以利用 TensorBoard 檢視的深度學習模型，實作手寫數字辨識的分類器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "1.7560884\n",
      "0.31652957\n",
      "0.36855695\n",
      "0.33571872\n",
      "0.24334337\n",
      "0.28673577\n",
      "0.29445466\n",
      "0.30991435\n",
      "0.33723766\n",
      "0.2996676\n",
      "0.30341798\n",
      "0.2813292\n",
      "0.2581301\n",
      "0.1429573\n",
      "0.23704624\n",
      "0.14751258\n",
      "0.2523249\n",
      "0.24465686\n",
      "0.27112776\n",
      "0.3467095\n",
      "---\n",
      "Accuracy: 0.9197\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 讀入 MNIST\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "# 設定參數\n",
    "learning_rate = 0.5\n",
    "training_steps = 1000\n",
    "batch_size = 100\n",
    "logs_path = 'TensorBoard/'\n",
    "n_features = x_train.shape[1]\n",
    "n_labels = y_train.shape[1]\n",
    "\n",
    "#建立 Feeds\n",
    "with tf.name_scope('Inputs'):\n",
    "    x = tf.placeholder(tf.float32, [None, n_features], name = 'Input_Data')\n",
    "with tf.name_scope('Labels'):\n",
    "    y = tf.placeholder(tf.float32, [None, n_labels], name = 'Label_Data')\n",
    "    \n",
    "# 建立 variables\n",
    "with tf.name_scope('ModelParameters'):\n",
    "    W = tf.Variable(tf.zeros([n_features, n_labels]), name = 'Weights')\n",
    "    b = tf.Variable(tf.zeros([n_labels]), name = 'Bias')\n",
    "    \n",
    "# 開始建構深度學習 Model\n",
    "with tf.name_scope('Model'):\n",
    "    # Softmax\n",
    "    prediction = tf.nn.softmax(tf.matmul(x, W) + b)\n",
    "\n",
    "with tf.name_scope('CrossEntropy'):\n",
    "    # Cross-entropy\n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y * tf.log(prediction), reduction_indices = 1))\n",
    "    tf.summary.scalar(\"Loss\", loss)\n",
    "with tf.name_scope('GradientDescent'):\n",
    "    # Gradient Descent\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "with tf.name_scope('Accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "    acc = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('Accuracy', acc)\n",
    "    \n",
    "# init\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# sess\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 視覺化\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logs_path, graph = tf.get_default_graph())\n",
    "\n",
    "# train\n",
    "for step in range(training_steps):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(optimizer, feed_dict = {x: batch_xs, y: batch_ys})\n",
    "    if step % 50 == 0:\n",
    "        print(sess.run(loss, feed_dict = {x: batch_xs, y: batch_ys}))\n",
    "        summary = sess.run(merged, feed_dict = {x: batch_xs, y: batch_ys})\n",
    "        writer.add_summary(summary, step)\n",
    "print(\"---\")\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", sess.run(acc, feed_dict = {x: x_test, y: y_test}))\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三十天 深度學習（4）卷積神經網絡與鐵人賽總結\n",
    "\n",
    "#### 使用神經網絡的套件 TensorFlow 來建立我們的第一個深度學習模型：卷積神經網絡（Convolutional Neural Network，CNN），來提升原本 92% 準確率的 MNIST 手寫數字辨識模型。卷積神經網絡廣泛被運用在圖片處理領域，我們很快地簡介她的特性。\n",
    "\n",
    "## 卷積神經網絡\n",
    "#### 卷積神經網絡要解決的問題源自於使用神經網絡辨識高解析度的彩色圖片，馬上會遭遇運算效能不足的難題，卷積神經網絡使用兩個方法來解決這個難題：\n",
    "\n",
    "## Convolution\n",
    "#### 有些特徵不需要看整張圖片才能捕捉起來，為了解決運算效能不足而採取將圖片解析度降維的方法，使用 Sub-sampling 或 Down-sampling 稱呼也許可以讓我們更容易瞭解她的意義。\n",
    "##### https://ithelp.ithome.com.tw/articles/10188044\n",
    "\n",
    "## Max-pooling\n",
    "#### 這是為了確保經過 Convolution 後圖片中的特徵可以被確實保留下來而採取的方法。\n",
    "\n",
    "#### 實作的深度練習模型除了導入 Convolution 與 Max-pooling 以外，還有三個地方與昨天不同：\n",
    "\n",
    "## 不同的 Activation Function\n",
    "#### 先前在添加神經網絡層的時候，如果沒有指定 Activation function 就是使用預設的線性函數，但是在 CNN 中會使用 ReLU（Rectified Linear Unit）作為 Activation function，模擬出非線性函數，確保神經元輸出的值在 0 到 1 之間。\n",
    "\n",
    "## 新增 Dropout 函數\n",
    "#### 用來避免過度配適（Overfitting）。\n",
    "\n",
    "## 更換 Optimizer\n",
    "#### 將先前一直使用的梯度遞減（Gradient descent）更換為 ADAM，是一個更進階且更成熟的梯度遞減演算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow 實作\n",
    "### 卷積神經網絡架構\n",
    "#### 我們來拆解一下接著要建立的卷積神經網絡架構：\n",
    "\n",
    "#### 輸入圖片（解析度 28x28 的手寫數字圖片）\n",
    "#### 第一層是 Convolution 層（32 個神經元），會利用解析度 5x5 的 filter 取出 32 個特徵，然後將圖片降維成解析度 14x14\n",
    "#### 第二層是 Convolution 層（64 個神經元），會利用解析度 5x5 的 filter 取出 64 個特徵，然後將圖片降維成解析度 7x7\n",
    "#### 第三層是 Densely Connected 層（1024 個神經元），會將圖片的 1024 個特徵攤平\n",
    "#### 輸出結果之前使用 Dropout 函數避免過度配適\n",
    "#### 第四層是輸出層（10 個神經元），使用跟之前相同的 Softmax 函數輸出結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Tensor(\"Label_19/Placeholder:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"ReadoutLayer_19/add:0\", shape=(?, 10), dtype=float32)\n",
      "step 0, training accuracy 0.06\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Label/Placeholder' with dtype float and shape [?,10]\n\t [[node Label/Placeholder (defined at <ipython-input-1-59896c0d788a>:21)  = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Label/Placeholder', defined at:\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1152, in inner\n    self.run()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1069, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-59896c0d788a>\", line 21, in <module>\n    y_ = tf.placeholder(tf.float32, shape = [None, n_labels])\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6251, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Label/Placeholder' with dtype float and shape [?,10]\n\t [[node Label/Placeholder (defined at <ipython-input-1-59896c0d788a>:21)  = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Label/Placeholder' with dtype float and shape [?,10]\n\t [[{{node Label/Placeholder}} = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2e7a5b2b73b8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mtrain_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"step %d, training accuracy %g\"\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Label/Placeholder' with dtype float and shape [?,10]\n\t [[node Label/Placeholder (defined at <ipython-input-1-59896c0d788a>:21)  = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Label/Placeholder', defined at:\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 832, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 605, in _run_callback\n    ret = callback()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1152, in inner\n    self.run()\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 1069, in run\n    yielded = self.gen.send(value)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 307, in wrapper\n    yielded = next(result)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2819, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2845, in _run_cell\n    return runner(coro)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3020, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3185, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3267, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-1-59896c0d788a>\", line 21, in <module>\n    y_ = tf.placeholder(tf.float32, shape = [None, n_labels])\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1747, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6251, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3274, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\ms022\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1770, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Label/Placeholder' with dtype float and shape [?,10]\n\t [[node Label/Placeholder (defined at <ipython-input-1-59896c0d788a>:21)  = Placeholder[dtype=DT_FLOAT, shape=[?,10], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# road mnist\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels\n",
    "\n",
    "# set param\n",
    "logs_path = 'TensorBoard/'\n",
    "n_features = x_train.shape[1]\n",
    "n_labels = y_train.shape[1]\n",
    "\n",
    "# 啟動 InteractiveSession\n",
    "sess = tf.InteractiveSession()\n",
    "with tf.name_scope('Input'):\n",
    "    x = tf.placeholder(tf.float32, shape = [None, n_features])\n",
    "with tf.name_scope('Label'):\n",
    "    y_ = tf.placeholder(tf.float32, shape = [None, n_labels])\n",
    "    print(y_)\n",
    "# 自訂初始化權重的函數\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 自訂 convolution 與 max-pooling function\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides = [1, 1, 1, 1], padding = 'SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1], padding = 'SAME')\n",
    "\n",
    "# 第一層是 Convolution 層（32 個神經元），會利用解析度 5x5 的 filter \n",
    "# 取出 32 個特徵，然後將圖片降維成解析度 14x14\n",
    "with tf.name_scope('FirstConvolutionLayer'):\n",
    "    W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "    b_conv1 = bias_variable([32])\n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    \n",
    "# 第二層是 Convolution 層（64 個神經元），會利用解析度 5x5 的 filter\n",
    "# 取出 64 個特徵，然後將圖片降維成解析度 7x7\n",
    "with tf.name_scope('SecondConvolutionLayer'):\n",
    "    W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "    b_conv2 = bias_variable([64])\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# 第三層是 Densely Connected 層（1024 個神經元），會將圖片的 1024 個特徵攤平\n",
    "with tf.name_scope('DenselyConnectedLayer'):\n",
    "    W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "    b_fc1 = bias_variable([1024])\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# 輸出結果之前使用 Dropout 函數避免過度配適\n",
    "with tf.name_scope('Dropout'):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 第四層是輸出層（10 個神經元），使用跟之前相同的 Softmax 函數輸出結果\n",
    "with tf.name_scope('ReadoutLayer'):\n",
    "    W_fc2 = weight_variable([1024, 10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    print(y_conv)\n",
    "#### BUG \n",
    "# 訓練與模型評估\n",
    "with tf.name_scope('CrossEntropy'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_conv, labels = y_))\n",
    "    tf.summary.scalar(\"CrossEntropy\", cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv,1), tf.argmax(y_,1))\n",
    "with tf.name_scope('Accuracy'):\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "\n",
    "# 初始化\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 將視覺化輸出\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(logs_path, graph = tf.get_default_graph())\n",
    "\n",
    "for i in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if i%100 == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "        summary = sess.run(merged, feed_dict = {x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "        writer.add_summary(summary, i)\n",
    "        writer.flush()\n",
    "    train_step.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict = {x: x_test, y_: y_test, keep_prob: 1.0}))\n",
    "\n",
    "# 關閉 session\n",
    "sess.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
